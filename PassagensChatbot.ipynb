{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ22pBRX98Rn"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "8u16EHBM-rtV",
        "outputId": "50d6a47b-2ab9-4fef-d506-eccafd1fcd0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-880a4cd4-4183-47dc-a8db-f06656e8fe8a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-880a4cd4-4183-47dc-a8db-f06656e8fe8a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dialogues_018.json to dialogues_018.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EVVnuFYREycJ"
      },
      "outputs": [],
      "source": [
        "# intents\n",
        "!mkdir -p dialogue_018/intents/NONE\n",
        "!mkdir -p dialogue_018/intents/SearchOnewayFlight\n",
        "!mkdir -p dialogue_018/intents/ReserveOnewayFlight\n",
        "!mkdir -p dialogue_018/intents/SearchRoundtripFlights\n",
        "!mkdir -p dialogue_018/intents/ReserveRoundtripFlights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPzqHs88CbQZ"
      },
      "source": [
        "Script para coletar apenas as utterances (frases) do usuário e armazená-las num diretório que representa a intenção(que será nossa classe para a tarefa de classificação de intenção).</br>\n",
        "<b>atenção</b>: O sistema foi excluído da coleta de utterances porque a resposta do sistema não possui intenção"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7mD2KTnt-Rg8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with open(\"dialogues_018.json\", 'r') as file:\n",
        "        data_018 = json.load(file)\n",
        "\n",
        "    for i in range(len(data_018)):\n",
        "        frames_amount = len(data_018[i]['turns'])\n",
        "        for j in range(frames_amount):\n",
        "            current_frame = data_018[i]['turns'][j]\n",
        "            speaker = current_frame['speaker']\n",
        "            if speaker == 'USER':\n",
        "                intent = current_frame['frames'][0]['state']['active_intent']\n",
        "                utterance = current_frame['utterance']\n",
        "\n",
        "                file_path = \"dialogue_018/intents/\" + intent + \"/\" + str(i) + \"_\" + str(j) + \".txt\"\n",
        "\n",
        "                f = open(file_path, \"w+\")\n",
        "                f.write(utterance)\n",
        "                f.close()\n",
        "\n",
        "                # Dados para o extrator de entidades\n",
        "                slots_dict = current_frame['frames'][0]['state']['slot_values']\n",
        "                all_values = [value for values in slots_dict.values() for value in values]\n",
        "\n",
        "                for each_value in all_values:\n",
        "                  base_path = \"dialogue_018/\" + each_value + \"/\"\n",
        "                  file_path_2 = \"dialogue_018/\" + each_value + \"/\" +  str(i) + \"_\" + str(j) + \".txt\"\n",
        "                  # Check if the directory exists\n",
        "                  if not os.path.exists(base_path):\n",
        "                      # If not, create the directory\n",
        "                      os.makedirs(base_path)\n",
        "                  f = open(file_path_2, \"w+\")\n",
        "                  f.write(utterance)\n",
        "                  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAPqnY0WDLev"
      },
      "source": [
        "Armazenar numa estrutura para treinamento no Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dados para o classificador"
      ],
      "metadata": {
        "id": "ZGBk9fky4MUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPmrl8B1TrRt",
        "outputId": "a28a0d60-887a-4786-9d6e-1982fe13d003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1052 files belonging to 5 classes.\n",
            "Using 842 files for training.\n",
            "Found 1052 files belonging to 5 classes.\n",
            "Using 210 files for validation.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds= tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/dialogue_018/intents',\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed,\n",
        "    shuffle=False)\n",
        "\n",
        "raw_validation_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/dialogue_018/intents',\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed,\n",
        "    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWFgAwDctR5W",
        "outputId": "59fd70ce-543f-4d1e-c420-4a79434b25d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NONE',\n",
              " 'ReserveOnewayFlight',\n",
              " 'ReserveRoundtripFlights',\n",
              " 'SearchOnewayFlight',\n",
              " 'SearchRoundtripFlights']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "raw_train_ds.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZMI9c_kFS5J"
      },
      "outputs": [],
      "source": [
        "for text_batch, label_batch in raw_train_ds:\n",
        "  print(\"Utterance: \", text_batch)\n",
        "  print(\"Label: \", label_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV7HzrCaIyWn",
        "outputId": "4da73636-3c76-4953-cfd8-5065e74695c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "print(raw_train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "seed = 42\n",
        "\n",
        "raw_extractor_train_ds= tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/dialogue_018/',\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed,\n",
        "    shuffle=False)\n",
        "\n",
        "raw_extractor_validation_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    '/content/dialogue_018/',\n",
        "    labels='inferred',\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5WFBaiQ4U0H",
        "outputId": "6b04fbbc-b2fa-42d1-baa2-30375c010a03"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8068 files belonging to 296 classes.\n",
            "Using 6455 files for training.\n",
            "Found 8068 files belonging to 296 classes.\n",
            "Using 1613 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_extractor_train_ds.class_names"
      ],
      "metadata": {
        "id": "ig4FaZPE4nbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dados para o extrator"
      ],
      "metadata": {
        "id": "rRSodEhZ4PIt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrVsXgbEJjjx"
      },
      "source": [
        "Acho que o Tensor acima é dividido em batches e acredito que isso adiciona uma complexidade na hora de tokenizar, pois teríamos que fazer para cada um dos tensores. Testei resolver fazer uma concatenação de todos os tensores abaixo:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensores para o classificador de intenções"
      ],
      "metadata": {
        "id": "wbX_9u0B40Eb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1o5cP6L6JLBx"
      },
      "outputs": [],
      "source": [
        "all_text_tensor = tf.concat([text_batch for text_batch, label_batch in raw_train_ds], axis=0)\n",
        "#all_text_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9Htct7EgLYae"
      },
      "outputs": [],
      "source": [
        "all_labels = tf.concat([label_batch for text_batch, label_batch in raw_train_ds], axis=0)\n",
        "#all_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S0j0NKdNMA-9"
      },
      "outputs": [],
      "source": [
        "utterances_validation_tensor = tf.concat([text_batch for text_batch, label_batch in raw_validation_ds], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zeozrI7tMGi3"
      },
      "outputs": [],
      "source": [
        "validation_labels = tf.concat([label_batch for text_batch, label_batch in raw_validation_ds], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensores para o extrator de entidades"
      ],
      "metadata": {
        "id": "bZ7tMp5b45cK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_texts_tensor = tf.concat([text_batch for text_batch, label_batch in raw_extractor_train_ds], axis=0)\n",
        "extractor_texts_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upLBd5JV37Ge",
        "outputId": "576bf05a-a2db-438b-d55d-da47bf62bff1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6455,), dtype=string, numpy=\n",
              "array([b'Yep that sounds good. What airport will I be flying into and what time will it arrive?',\n",
              "       b'Thanks for your help.', b'No, that will be all.', ...,\n",
              "       b'That is great.', b'Thanks. That is all.',\n",
              "       b'That is good. Can you buy me tickets?'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_labels_tensor = tf.concat([label_batch for text_batch, label_batch in raw_extractor_train_ds], axis=0)\n",
        "extractor_labels_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD__Ul9v5Bkv",
        "outputId": "a5b323cf-1cf2-4081-c2ec-7ceee4ad2300"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6455,), dtype=int32, numpy=array([  0,   0,   0, ..., 251, 251, 251], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_validation_tensor = tf.concat([text_batch for text_batch, label_batch in raw_extractor_validation_ds], axis=0)"
      ],
      "metadata": {
        "id": "j5HDvcjT5RpS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_validation_labels = tf.concat([label_batch for text_batch, label_batch in raw_extractor_validation_ds], axis=0)"
      ],
      "metadata": {
        "id": "lZbNVCb25bxI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug1zDO2rMFLk"
      },
      "source": [
        "# Pre processamento de dados\n",
        "Fazer uma bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v7s5l7y6WWlB"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "import json\n",
        "import numpy\n",
        "from keras.preprocessing import text, sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZj_2SooMm8V"
      },
      "source": [
        "### Train subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWpBBYtYWdxe"
      },
      "outputs": [],
      "source": [
        "t = Tokenizer()\n",
        "texts = all_text_tensor.numpy().astype(str)\n",
        "t.fit_on_texts(texts)\n",
        "\n",
        "#print(t.document_count)\n",
        "print(t.word_index)\n",
        "#print(t.word_docs)\n",
        "# integer encode documents\n",
        "encoded_docs = t.texts_to_matrix(texts, mode='count')\n",
        "print(encoded_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HpdgcAJ2hTvw"
      },
      "outputs": [],
      "source": [
        "seq_token = t.texts_to_sequences(texts)\n",
        "padded_sequences = sequence.pad_sequences(seq_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU7wKRXIh_XI",
        "outputId": "2d4baf16-22c2-435d-889a-54c953f5ffbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(842, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "padded_sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do62_JxXN6s3",
        "outputId": "85614c34-cbca-42c9-cc70-0158f74e1df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([842])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "all_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EYJ9PZOMq-w"
      },
      "source": [
        "### Validation subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xWtIC13BMtHB"
      },
      "outputs": [],
      "source": [
        "t2 = Tokenizer()\n",
        "validation_texts = utterances_validation_tensor.numpy().astype(str)\n",
        "t2.fit_on_texts(validation_texts)\n",
        "validation_seq_token = t2.texts_to_sequences(validation_texts)\n",
        "padded_validation = sequence.pad_sequences(validation_seq_token)\n",
        "#padded_validation = sequence.pad_sequences(validation_seq_token, maxlen=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlKhpjirNkUA",
        "outputId": "9a144a91-b941-44cd-f34b-d23a6cd715a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "padded_validation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Xna25DNty1",
        "outputId": "3f3582f6-e8e1-41b8-e1a8-6f026aeb606a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([210])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "validation_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vrd0nYb4IDGn"
      },
      "source": [
        "# Classificação de intenções (Parte 1)\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM </br>\n",
        "https://keras.io/examples/nlp/text_classification_with_transformer/ </br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHp8IuBtIqbn"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG-26GAEZWk8",
        "outputId": "21ae3737-53ec-441b-b360-e8b777345e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         84200     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                42240     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126765 (495.18 KB)\n",
            "Trainable params: 126765 (495.18 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LSTM\n",
        "from keras.layers import Embedding\n",
        "import keras.backend as K\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(input_dim=842, output_dim=100))\n",
        "model_lstm.add(LSTM(units=64))\n",
        "model_lstm.add(Dense(5,activation='softmax'))\n",
        "model_lstm.compile(loss=['sparse_categorical_crossentropy'] , optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrIhK-kabC9H",
        "outputId": "5fba4f10-a148-4336-d429-5d32fbbfed2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 4s 22ms/step - loss: 1.3942 - accuracy: 0.4893\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 1.0900 - accuracy: 0.6081\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 0.8570 - accuracy: 0.7114\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 1s 35ms/step - loss: 0.6896 - accuracy: 0.7435\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.6102 - accuracy: 0.7969\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.5513 - accuracy: 0.8124\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.4720 - accuracy: 0.8325\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 1s 21ms/step - loss: 0.4157 - accuracy: 0.8610\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.3640 - accuracy: 0.8765\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.3428 - accuracy: 0.8848\n"
          ]
        }
      ],
      "source": [
        "history_lstm = model_lstm.fit(padded_sequences, all_labels, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzf3mFBgMOpB",
        "outputId": "3cda8eab-1a52-4577-b006-98219c1895c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 4s 48ms/step - loss: 1.3926 - accuracy: 0.4287 - val_loss: 0.8451 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 1.1208 - accuracy: 0.6045 - val_loss: 0.8833 - val_accuracy: 0.6857\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.8520 - accuracy: 0.6995 - val_loss: 0.8679 - val_accuracy: 0.6286\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.6662 - accuracy: 0.7565 - val_loss: 1.5056 - val_accuracy: 0.4905\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.5582 - accuracy: 0.8207 - val_loss: 1.3898 - val_accuracy: 0.5619\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.4805 - accuracy: 0.8504 - val_loss: 1.8051 - val_accuracy: 0.4810\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.4161 - accuracy: 0.8563 - val_loss: 2.0225 - val_accuracy: 0.4286\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 1s 22ms/step - loss: 0.3758 - accuracy: 0.8610 - val_loss: 1.7235 - val_accuracy: 0.5619\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 1s 23ms/step - loss: 0.3464 - accuracy: 0.8729 - val_loss: 2.0350 - val_accuracy: 0.4810\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 1s 24ms/step - loss: 0.3123 - accuracy: 0.8884 - val_loss: 2.4912 - val_accuracy: 0.3952\n"
          ]
        }
      ],
      "source": [
        "history_with_validation_lstm = model_lstm.fit(padded_sequences, all_labels, validation_data=(padded_validation, validation_labels), epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfWznDhyI9qE"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "with open(\"dialogues_018.json\", 'r') as file:\n",
        "    data_018 = json.load(file)\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(data_018)):\n",
        "    frames_amount = len(data_018[i]['turns'])\n",
        "    for j in range(frames_amount):\n",
        "        current_frame = data_018[i]['turns'][j]\n",
        "        speaker = current_frame['speaker']\n",
        "        if speaker == 'USER':\n",
        "            intent = current_frame['frames'][0]['state']['active_intent']\n",
        "            utterance = current_frame['utterance']\n",
        "            texts.append(utterance)\n",
        "            labels.append(intent)\n",
        "\n",
        "texts_train, texts_validation, labels_train, labels_validation = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(texts_train)\n",
        "X_validation = vectorizer.transform(texts_validation)\n",
        "\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train, labels_train)\n",
        "\n",
        "predictions = svm_model.predict(X_validation)\n",
        "\n",
        "accuracy = accuracy_score(labels_validation, predictions)\n",
        "print(f'Acurácia do modelo SVM: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNy6bwDU8j3B",
        "outputId": "1018d849-02f6-4d7c-d2b8-1daf9e29c6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo SVM: 0.8104265402843602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de diálogo\n",
        "example_dialogue = [\n",
        "    {\"speaker\": \"USER\", \"utterance\": \"I would like a short trip to New York\"}\n",
        "    # Adicione mais turnos do diálogo conforme necessário\n",
        "]\n",
        "\n",
        "# Pré-processamento do exemplo de diálogo\n",
        "example_text = example_dialogue[0]['utterance']\n",
        "example_vector = vectorizer.transform([example_text])\n",
        "\n",
        "# Previsão do modelo SVM\n",
        "predicted_intent = svm_model.predict(example_vector)\n",
        "\n",
        "# Resultados\n",
        "print(f\"Texto do Usuário: {example_text}\")\n",
        "print(f\"Intenção Prevista: {predicted_intent[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVX4CJlF-d2r",
        "outputId": "c3284575-5c5a-4cfa-891d-340bef9d8862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto do Usuário: I would like a short trip to New York\n",
            "Intenção Prevista: SearchRoundtripFlights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EtR1gk5I_4A"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.preprocessing.text import Tokenizer, one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JToZVtBNKY24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=842, output_dim=100))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Alterado para categorical_crossentropy\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Convertendo os rótulos para codificação one-hot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "labels_one_hot = to_categorical(all_labels, num_classes=5)\n",
        "\n",
        "# Fit do modelo\n",
        "history = model.fit(padded_sequences, labels_one_hot, epochs=10, validation_data=(padded_validation, to_categorical(validation_labels, num_classes=5)), batch_size=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQFSwl2lODBX",
        "outputId": "c89296a0-b2be-4663-df84-d0d50a769a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, None, 100)         84200     \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, None, 128)         64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_8 (Gl  (None, 128)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 156909 (612.93 KB)\n",
            "Trainable params: 156909 (612.93 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "169/169 [==============================] - 6s 28ms/step - loss: 0.9865 - accuracy: 0.6496 - val_loss: 1.3784 - val_accuracy: 0.4571\n",
            "Epoch 2/10\n",
            "169/169 [==============================] - 1s 9ms/step - loss: 0.5180 - accuracy: 0.8325 - val_loss: 1.8332 - val_accuracy: 0.4333\n",
            "Epoch 3/10\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.3749 - accuracy: 0.8717 - val_loss: 2.7881 - val_accuracy: 0.2571\n",
            "Epoch 4/10\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.2939 - accuracy: 0.8907 - val_loss: 1.9813 - val_accuracy: 0.4667\n",
            "Epoch 5/10\n",
            "169/169 [==============================] - 1s 7ms/step - loss: 0.2171 - accuracy: 0.9240 - val_loss: 2.2794 - val_accuracy: 0.4476\n",
            "Epoch 6/10\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1757 - accuracy: 0.9371 - val_loss: 2.6466 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1445 - accuracy: 0.9477 - val_loss: 2.5176 - val_accuracy: 0.4286\n",
            "Epoch 8/10\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1246 - accuracy: 0.9525 - val_loss: 2.7134 - val_accuracy: 0.4667\n",
            "Epoch 9/10\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1086 - accuracy: 0.9596 - val_loss: 3.5510 - val_accuracy: 0.3095\n",
            "Epoch 10/10\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9572 - val_loss: 4.1802 - val_accuracy: 0.2714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que você tenha um novo texto a ser classificado\n",
        "new_text = \"i need to buy a one way flight\"\n",
        "\n",
        "new_sequence = t.texts_to_sequences([new_text])\n",
        "padded_new_sequence = pad_sequences(new_sequence, maxlen=10, padding='post')\n",
        "\n",
        "predictions = model.predict(padded_new_sequence)\n",
        "\n",
        "predicted_class = predictions.argmax(axis=-1)\n",
        "\n",
        "print(f'O texto foi classificado como classe: {predicted_class[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91BRkozEPtpF",
        "outputId": "c7934442-b528-49aa-9d23-4463138da374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 115ms/step\n",
            "O texto foi classificado como classe: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G75RfMxsHgcO"
      },
      "source": [
        "## Teste de transformer com BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BusOX61MHjt4"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_NIt4xuH4aU",
        "outputId": "1cb26ad9-6133-4a65-e38d-beb3572a6c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load BERT tokenizer and model\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0Q_FlMyMhsT"
      },
      "outputs": [],
      "source": [
        "# Modify the model's classifier layer\n",
        "classifier_layer = Dense(5, activation='softmax',  name='classifier')\n",
        "bert_model.layers[-1]= classifier_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc16HSmWJXsR"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "opt = keras.optimizers.Adam(learning_rate=2e-5)\n",
        "bert_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_E03K1sJpWX",
        "outputId": "0e5ae41c-eba8-43c0-cea6-6dd86e2ed5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "27/27 [==============================] - 328s 11s/step - loss: 3.1591 - accuracy: 0.3753\n",
            "Epoch 2/3\n",
            "27/27 [==============================] - 279s 10s/step - loss: 1.9506 - accuracy: 0.3717\n",
            "Epoch 3/3\n",
            "27/27 [==============================] - 283s 10s/step - loss: 1.4578 - accuracy: 0.4204\n"
          ]
        }
      ],
      "source": [
        "bert_history = bert_model.fit(\n",
        "    padded_sequences,\n",
        "    all_labels,\n",
        "    epochs=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extrator de entidades (Parte 2)\n",
        "Podemos definir algumas entidades:\n",
        "- Flight number\n",
        "- Airline\n",
        "- Departure time\n",
        "- Arrival time\n",
        "- Flight duration\n",
        "- Amount of passengers"
      ],
      "metadata": {
        "id": "oaKEUB_6OBOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM (Extrator)"
      ],
      "metadata": {
        "id": "p3GMncDqeypl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = Tokenizer()\n",
        "texts = extractor_texts_tensor.numpy().astype(str)\n",
        "t3.fit_on_texts(texts)\n",
        "seq_token = t3.texts_to_sequences(texts)\n",
        "padded_sequences_extractor_lstm = sequence.pad_sequences(seq_token)"
      ],
      "metadata": {
        "id": "Fnxv8fMU3nx3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "extractor_lstm = Sequential()\n",
        "extractor_lstm.add(Embedding(input_dim=6455, output_dim=50))\n",
        "extractor_lstm.add(LSTM(units=32))\n",
        "# The number of units in Dense layer should be equal to the number of entity labels + 1\n",
        "extractor_lstm.add(Dense(296, activation='softmax'))\n",
        "extractor_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "extractor_lstm.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6jeGkILe9PC",
        "outputId": "e29ddb1c-e0fe-4915-c3c0-4e6535ec5e68"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, None, 50)          322750    \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 32)                10624     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 296)               9768      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 343142 (1.31 MB)\n",
            "Trainable params: 343142 (1.31 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_extractor_lstm = extractor_lstm.fit(padded_sequences_extractor_lstm, extractor_labels_tensor, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSmc87LEhIsn",
        "outputId": "4e9a24aa-62a9-44bc-e4b8-a0e9581c0063"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "202/202 [==============================] - 6s 19ms/step - loss: 5.0062 - accuracy: 0.0542\n",
            "Epoch 2/10\n",
            "202/202 [==============================] - 5s 25ms/step - loss: 4.7712 - accuracy: 0.0634\n",
            "Epoch 3/10\n",
            "202/202 [==============================] - 4s 19ms/step - loss: 4.7628 - accuracy: 0.0626\n",
            "Epoch 4/10\n",
            "202/202 [==============================] - 4s 19ms/step - loss: 4.7561 - accuracy: 0.0634\n",
            "Epoch 5/10\n",
            "202/202 [==============================] - 5s 25ms/step - loss: 4.7491 - accuracy: 0.0634\n",
            "Epoch 6/10\n",
            "202/202 [==============================] - 4s 19ms/step - loss: 4.7428 - accuracy: 0.0652\n",
            "Epoch 7/10\n",
            "202/202 [==============================] - 4s 19ms/step - loss: 4.7332 - accuracy: 0.0660\n",
            "Epoch 8/10\n",
            "202/202 [==============================] - 5s 24ms/step - loss: 4.7244 - accuracy: 0.0679\n",
            "Epoch 9/10\n",
            "202/202 [==============================] - 4s 20ms/step - loss: 4.7152 - accuracy: 0.0669\n",
            "Epoch 10/10\n",
            "202/202 [==============================] - 4s 19ms/step - loss: 4.7042 - accuracy: 0.0680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer (Extrator)"
      ],
      "metadata": {
        "id": "XHFvEJP_e1xd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NruSNAF0jfUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversação"
      ],
      "metadata": {
        "id": "VyfJWXMsO0Nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(user_input):\n",
        "  t = Tokenizer()\n",
        "  t.fit_on_texts(user_input)\n",
        "  seq_token = t.texts_to_sequences([user_input])\n",
        "  padded_sequences = sequence.pad_sequences(seq_token)\n",
        "  return padded_sequences"
      ],
      "metadata": {
        "id": "c1Li5WD1QL-i"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def classify_intent(preprocessed_input):\n",
        "  predictions = model_lstm.predict(np.array(preprocessed_input))\n",
        "\n",
        "  predicted_intent_index = np.argmax(predictions)\n",
        "  confidence = predictions[0][predicted_intent_index]\n",
        "\n",
        "  intents = [\"ReserveOnewayFlight\", \"SearchOnewayFlight\", \"SearchRoundtripFlights\", \"ReserveRoundtripFlights\", \"NONE\"]\n",
        "\n",
        "  predicted_intent = intents[predicted_intent_index]\n",
        "\n",
        "  return predicted_intent, confidence"
      ],
      "metadata": {
        "id": "FvHMYWXTQTT7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities(preprocessed_input):\n",
        "  predictions = extractor_lstm.predict(preprocessed_input)\n",
        "  possible_entities = raw_extractor_train_ds.class_names\n",
        "  entity_labels = [possible_entities[i] for i, pred in enumerate(predictions[0]) if pred > 0.5]\n",
        "\n",
        "  return entity_labels"
      ],
      "metadata": {
        "id": "iNK2-jkSQYPC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(combined_info):\n",
        "  pass"
      ],
      "metadata": {
        "id": "jp6wh03bQeMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"User: \")\n",
        "\n",
        "  if user_input == \"Bye\":\n",
        "    break\n",
        "\n",
        "  preprocessed_input = preprocess_input(user_input)\n",
        "  #print(preprocessed_input.shape)\n",
        "\n",
        "  # Intent Classification\n",
        "  intent, confidence = classify_intent(preprocessed_input)\n",
        "\n",
        "  # Entity Extraction\n",
        "  entities = extract_entities(preprocessed_input)\n",
        "\n",
        "  # Combine Information\n",
        "  combined_info = {'intent': intent, 'confidence': confidence, 'entities': entities}\n",
        "\n",
        "  # Dialogue Management and Response Generation\n",
        "  #response = generate_response(combined_info)\n",
        "\n",
        "  print(f\"Intent: {intent}, Confidence: {confidence}\")\n",
        "  print(f\"Entities: {entities}\")\n",
        "  #print(f\"Bot: {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKQcw1W0PDYG",
        "outputId": "0efbd7ad-58a4-454d-b2f0-fa9c2cf0c48f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: I would like a one way flight to Atlanta\n",
            "1/1 [==============================] - 0s 448ms/step\n",
            "1/1 [==============================] - 0s 436ms/step\n",
            "Intent: SearchRoundtripFlights, Confidence: 0.4188711643218994\n",
            "Entities: []\n",
            "User: Bye\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zfWznDhyI9qE",
        "7EtR1gk5I_4A",
        "G75RfMxsHgcO"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}